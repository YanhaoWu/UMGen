<div align="center">
<img src="assets/UMGen_Logo.png" width="120">
<!-- <h1>UMGen</h1> -->

### [Generating Multimodal Driving Scenes via Next-Scene Prediction](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Generating_Multimodal_Driving_Scenes_via_Next-Scene_Prediction_CVPR_2025_paper.pdf)

[Yanhao Wu](https://yanhaowu.github.io/UMGen)<sup>1,2</sup>, [Haoyang Zhang](https://scholar.google.com.hk/citations?user=PlMpgeIAAAAJ&hl=zh-CN&oi=ao)<sup>2</sup>, [Tianwei Lin](https://wzmsltw.github.io/)<sup>2</sup>, [Lichao Huang](https://scholar.google.com/citations?user=F2e_jZMAAAAJ&hl=en&oi=ao/)<sup>2</sup>, 

[Shujie Luo](https://scholar.google.com.hk/citations?user=BDaj_esAAAAJ&hl=zh-CN&oi=ao/)<sup>2</sup>, [Rui Wu](https://scholar.google.com.hk/citations?user=Z_ZkkbEAAAAJ&hl=zh-CN&oi=ao/)<sup>2</sup>, [Congpei Qiu](https://congpeiqiu.github.io)<sup>1</sup>, [Wei Ke](https://gr.xjtu.edu.cn/en/web/wei.ke/home/)<sup>1</sup>, [Tong Zhang](https://scholar.google.com/citations?user=kCy8JG8AAAAJ&hl=en&oi=ao)<sup>3, 4</sup>,
 
<sup>1</sup> Xi'an Jiaotong University, <sup>2</sup> Horizon Robotics, <sup>3</sup> EPFL, <sup>4</sup> University of Chinese Academy of Sciences

Accepted to CVPR 2025

[![UMGen](https://img.shields.io/badge/ProjectPage-UMGen-blue)](https://yanhaowu.github.io/UMGen/)&nbsp;
[![Paper](https://img.shields.io/badge/Paper-UMGen-blue)](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Generating_Multimodal_Driving_Scenes_via_Next-Scene_Prediction_CVPR_2025_paper.pdf)&nbsp;
</div>


## ğŸŒŸ What is UMGen?

UMGen generates **multimodal driving scenes**, where each scene integrates:  
**Ego-vehicle actions**, **maps**, **traffic agents**, and **images**.  

### ğŸ¬ Autoregressive Scene Generation
<p style="margin-bottom:4px;">
<strong> All visual elements</strong> in the video are generated by UMGen.
</p>

<!-- <video width="640" height="360" controls style="display:block; margin-top:-60px;">
  <source src="assets/Teaser_formated.gif" type="video/mp4">
</video> -->
<!-- [Teaser_Video](assets/Teaser_formated.gif) -->
https://github.com/user-attachments/assets/afe62434-1a9e-44dc-b1bd-b67d48e1b693


### ğŸ¤– User-Specified Scenario Generation
UMGen also supports **user-specified scenario generation**.  
In this video, we control the agent to simulate a **cut-in maneuver scenario**.

https://github.com/user-attachments/assets/a3224d85-08df-4e36-a47d-f3e88f2b7ad6

### ğŸ“ More Information
For more videos and details, please refer to our  [![Paper](https://img.shields.io/badge/Paper-UMGen-blue)](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Generating_Multimodal_Driving_Scenes_via_Next-Scene_Prediction_CVPR_2025_paper.pdf)  and  [![UMGen](https://img.shields.io/badge/ProjectPage-UMGen-blue)](https://yanhaowu.github.io/UMGen/)





## ğŸš€ Quick Start
### Set up a new virtual environment
```bash
conda create -n UMGen python=3.8 -y
conda activate UMGen
```
### Install dependency packpages
```bash
UMGen_path="path/to/UMGen"
cd ${UMGen_path}
pip3 install --upgrade pip
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
pip3 install -r requirements.txt
```

### Prepare the data
Download the tokenized data and pretrained weights from https://drive.google.com/drive/folders/1rJEVxWNk4MH_FPdqUMgdjV_PHwKJMS-3?usp=sharing

The directory structure should be:
```bash
UMGen/
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ controlled_scenes/
|       â”œâ”€â”€ XX
â”‚   â”œâ”€â”€ tokenized_origin_scenes/
â”‚       â”œâ”€â”€ XX
|   â”œâ”€â”€ weights/
â”‚       â”œâ”€â”€ image_var.tar
|       â”œâ”€â”€ map_vae.ckpt
|       â”œâ”€â”€ UMGen_Large.pt
â””â”€â”€ projects/
```


## âš™ï¸ Inference Usage
### ğŸ›ï¸ Infer Future Frames Freely  
Generate future frames automatically without any external control signals.
```bash
python projects/tools/evaluate.py --infer_task video --set_num_new_frames 30
```

### ğŸ•¹ï¸Infer Future Frames with Control
Generate future frames under specific control constraints, such as predefined trajectories or object behavior control.
```bash
python projects/tools/evaluate.py --infer_task control --set_num_new_frames 30
```

---

## ğŸ§© To-Do List

- [ ] Release more **tokenized scene data**
- [ ] Release the **code for obtaining scene tokens** using the VAE models
- [ ] Release the **diffusion code** to enhance the videos

---

## ğŸ“¬ Contact
For any questions or collaborations, feel free to contact me : )
ğŸ“§ **[wuyanhao@stu.xjtu.edu.cn](mailto:wuyanhao@stu.xjtu.edu.cn)**
